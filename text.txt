remove duplicate
depths = numpy.unique(lc_cache_overview['depth'])
in " for duration in durations:"


durations = numpy.unique(lc_cache_overview['width_in_samples'])
            depths = numpy.unique(lc_cache_overview['depth'])
			
with a pre-computed list of unique values




if use_cores == 1:
        print('Running on 1 core')
        pbar = tqdm(total=numpy.size(periods))
        for period in periods:
            data = search_period(
                period=period,
                time_series=time_series,
                injected=injected,
                weights=weights,
                lc_cache=lc_cache,
                lc_cache_overview=lc_cache_overview,
                algo=algo)
            test_statistic_periods.append(data[0])
            test_statistic_residuals.append(data[1])
            test_statistic_rolls.append(data[2])
            test_statistic_rows.append(data[3])
            pbar.update(1)
